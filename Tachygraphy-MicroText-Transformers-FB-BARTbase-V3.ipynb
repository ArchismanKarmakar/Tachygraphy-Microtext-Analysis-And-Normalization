{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4b5b7578",
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "execution": {
     "iopub.execute_input": "2025-03-01T11:03:48.282624Z",
     "iopub.status.busy": "2025-03-01T11:03:48.282316Z",
     "iopub.status.idle": "2025-03-01T11:03:49.017827Z",
     "shell.execute_reply": "2025-03-01T11:03:49.016755Z"
    },
    "papermill": {
     "duration": 0.750013,
     "end_time": "2025-03-01T11:03:49.019065",
     "exception": false,
     "start_time": "2025-03-01T11:03:48.269052",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/kaggle/input/dataset-tachygraphy/Tachygraphy_EmotionMoodtags_Dataset.csv\n",
      "/kaggle/input/dataset-tachygraphy/Tachygraphy_MicroText-AIO-V3.xlsx\n",
      "/kaggle/input/dataset-tachygraphy/Tachygraphy_dataset_main.csv\n",
      "/kaggle/input/dataset-tachygraphy/Tachygraphy_MicroText-AIO-V2.xlsx\n"
     ]
    }
   ],
   "source": [
    "# This Python 3 environment comes with many helpful analytics libraries installed\n",
    "# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n",
    "# For example, here's several helpful packages to load\n",
    "\n",
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "\n",
    "# Input data files are available in the read-only \"../input/\" directory\n",
    "# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n",
    "\n",
    "import os\n",
    "for dirname, _, filenames in os.walk('/kaggle/input'):\n",
    "    for filename in filenames:\n",
    "        print(os.path.join(dirname, filename))\n",
    "\n",
    "# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n",
    "# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "fe07dcde",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-01T11:03:49.044790Z",
     "iopub.status.busy": "2025-03-01T11:03:49.044446Z",
     "iopub.status.idle": "2025-03-01T11:03:50.067182Z",
     "shell.execute_reply": "2025-03-01T11:03:50.066517Z"
    },
    "papermill": {
     "duration": 1.036637,
     "end_time": "2025-03-01T11:03:50.068812",
     "exception": false,
     "start_time": "2025-03-01T11:03:49.032175",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "dataset = pd.read_excel('/kaggle/input/dataset-tachygraphy/Tachygraphy_MicroText-AIO-V3.xlsx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6a4a8619",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-01T11:03:50.092547Z",
     "iopub.status.busy": "2025-03-01T11:03:50.092137Z",
     "iopub.status.idle": "2025-03-01T11:03:50.095654Z",
     "shell.execute_reply": "2025-03-01T11:03:50.094834Z"
    },
    "papermill": {
     "duration": 0.016439,
     "end_time": "2025-03-01T11:03:50.096892",
     "exception": false,
     "start_time": "2025-03-01T11:03:50.080453",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "df = dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4bf9bb07",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-01T11:03:50.120429Z",
     "iopub.status.busy": "2025-03-01T11:03:50.120092Z",
     "iopub.status.idle": "2025-03-01T11:03:50.126300Z",
     "shell.execute_reply": "2025-03-01T11:03:50.125444Z"
    },
    "papermill": {
     "duration": 0.019525,
     "end_time": "2025-03-01T11:03:50.127576",
     "exception": false,
     "start_time": "2025-03-01T11:03:50.108051",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "df.rename(columns={'Informal Text':'input', 'Expanded Meaning':'target'}, inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c80e31a7",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-01T11:03:50.151228Z",
     "iopub.status.busy": "2025-03-01T11:03:50.150933Z",
     "iopub.status.idle": "2025-03-01T11:03:50.169029Z",
     "shell.execute_reply": "2025-03-01T11:03:50.168255Z"
    },
    "papermill": {
     "duration": 0.031212,
     "end_time": "2025-03-01T11:03:50.170346",
     "exception": false,
     "start_time": "2025-03-01T11:03:50.139134",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>input</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>omg, JEE prep is killing me rn</td>\n",
       "      <td>Oh my god, Joint Entrance Examination preparat...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>u up 4 a break b4 UPSC revision?</td>\n",
       "      <td>Are you up for a break before Union Public Ser...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ttyl, finishing da CAT mock</td>\n",
       "      <td>Talk to you later, finishing the Common Admiss...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>nah, dat GATE paper was brutal af</td>\n",
       "      <td>No, that Graduate Aptitude Test in Engineering...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>sup? u done w/ ur IIT assignment?</td>\n",
       "      <td>What's up? Are you done with your Indian Insti...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                               input  \\\n",
       "0     omg, JEE prep is killing me rn   \n",
       "1   u up 4 a break b4 UPSC revision?   \n",
       "2        ttyl, finishing da CAT mock   \n",
       "3  nah, dat GATE paper was brutal af   \n",
       "4  sup? u done w/ ur IIT assignment?   \n",
       "\n",
       "                                              target  \n",
       "0  Oh my god, Joint Entrance Examination preparat...  \n",
       "1  Are you up for a break before Union Public Ser...  \n",
       "2  Talk to you later, finishing the Common Admiss...  \n",
       "3  No, that Graduate Aptitude Test in Engineering...  \n",
       "4  What's up? Are you done with your Indian Insti...  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "76af8eac",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-01T11:03:50.194316Z",
     "iopub.status.busy": "2025-03-01T11:03:50.194063Z",
     "iopub.status.idle": "2025-03-01T11:03:50.198610Z",
     "shell.execute_reply": "2025-03-01T11:03:50.198009Z"
    },
    "papermill": {
     "duration": 0.017625,
     "end_time": "2025-03-01T11:03:50.199797",
     "exception": false,
     "start_time": "2025-03-01T11:03:50.182172",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "df['input'] = df['input'].astype(str)\n",
    "df['target'] = df['target'].astype(str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "cee1278b",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-01T11:03:50.223023Z",
     "iopub.status.busy": "2025-03-01T11:03:50.222781Z",
     "iopub.status.idle": "2025-03-01T11:04:16.227484Z",
     "shell.execute_reply": "2025-03-01T11:04:16.226748Z"
    },
    "papermill": {
     "duration": 26.017816,
     "end_time": "2025-03-01T11:04:16.229055",
     "exception": false,
     "start_time": "2025-03-01T11:03:50.211239",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.utils.data import DataLoader\n",
    "from transformers import BartTokenizer, BartForConditionalGeneration, AdamW, BertModel, BertTokenizer\n",
    "# from torch.cuda.amp import autocast, GradScaler\n",
    "from datasets import load_dataset\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "import ray\n",
    "from ray import tune\n",
    "import torch.nn as nn\n",
    "\n",
    "from torch.optim import AdamW\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from transformers import RobertaTokenizer, RobertaModel\n",
    "from sklearn.model_selection import train_test_split\n",
    "import optuna\n",
    "# from optuna.integration import PyTorchLightningPruner\n",
    "from ray import tune\n",
    "import ray\n",
    "from ray import tune\n",
    "from ray.tune import CLIReporter\n",
    "from ray.tune import CLIReporter\n",
    "from ray.tune.schedulers import ASHAScheduler\n",
    "from ray.tune.schedulers import ASHAScheduler\n",
    "# from ray.tune.integration.pytorch import TuneReportCallback\n",
    "from torch.amp import GradScaler, autocast\n",
    "# from ray.tune.integration.optuna import OptunaSearch\n",
    "from ray.tune.search.optuna import OptunaSearch\n",
    "from ray import tune\n",
    "from ray.tune.search.hyperopt import HyperOptSearch\n",
    "from torch import autocast\n",
    "# from ray import tune\n",
    "# from ray.tune.integration.tensorboard import TensorBoardReporter\n",
    "from ray.tune.logger import TBXLogger\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "from ray.train import report\n",
    "# from ray.tune.integration.jupyter import JupyterNotebookReporter\n",
    "from ray.tune import JupyterNotebookReporter\n",
    "# from torch.cuda.amp import GradScaler, autocast\n",
    "from torch.optim.lr_scheduler import StepLR, CosineAnnealingLR\n",
    "from ray.tune.schedulers import HyperBandScheduler, AsyncHyperBandScheduler\n",
    "\n",
    "\n",
    "import os\n",
    "import gc\n",
    "import re\n",
    "import ast\n",
    "import sys\n",
    "import copy\n",
    "import json\n",
    "import time\n",
    "import math\n",
    "import string\n",
    "import pickle\n",
    "import random\n",
    "import joblib\n",
    "import itertools\n",
    "import warnings\n",
    "\n",
    "\n",
    "import emoji\n",
    "from bs4 import BeautifulSoup\n",
    "import os\n",
    "import re\n",
    "import string\n",
    "import json\n",
    "\n",
    "\n",
    "import argparse # CPMP\n",
    "\n",
    "import scipy as sp\n",
    "\n",
    "from tqdm.auto import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c5e750ce",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-01T11:04:16.254416Z",
     "iopub.status.busy": "2025-03-01T11:04:16.253653Z",
     "iopub.status.idle": "2025-03-01T11:04:16.272042Z",
     "shell.execute_reply": "2025-03-01T11:04:16.271201Z"
    },
    "papermill": {
     "duration": 0.032526,
     "end_time": "2025-03-01T11:04:16.273515",
     "exception": false,
     "start_time": "2025-03-01T11:04:16.240989",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "contraction_mapping = {\"ain't\": \"is not\", \"aren't\": \"are not\",\"can't\": \"cannot\", \"'cause\": \"because\", \"could've\": \"could have\", \"couldn't\": \"could not\", \n",
    "                       \"didn't\": \"did not\",  \"doesn't\": \"does not\", \"don't\": \"do not\", \"hadn't\": \"had not\", \"hasn't\": \"has not\", \"haven't\": \"have not\", \n",
    "                       \"he'd\": \"he would\",\"he'll\": \"he will\", \"he's\": \"he is\", \"how'd\": \"how did\", \"how'd'y\": \"how do you\", \"how'll\": \"how will\", \n",
    "                       \"how's\": \"how is\",  \"I'd\": \"I would\", \"I'd've\": \"I would have\", \"I'll\": \"I will\", \"I'll've\": \"I will have\",\"I'm\": \"I am\",\n",
    "                       \"I've\": \"I have\", \"i'd\": \"i would\", \"i'd've\": \"i would have\", \"i'll\": \"i will\",  \"i'll've\": \"i will have\",\"i'm\": \"i am\", \n",
    "                       \"i've\": \"i have\", \"isn't\": \"is not\", \"it'd\": \"it would\", \"it'd've\": \"it would have\", \"it'll\": \"it will\", \"it'll've\": \"it will have\",\n",
    "                       \"it's\": \"it is\", \"let's\": \"let us\", \"ma'am\": \"madam\", \"mayn't\": \"may not\", \"might've\": \"might have\",\"mightn't\": \"might not\",\n",
    "                       \"mightn't've\": \"might not have\", \"must've\": \"must have\", \"mustn't\": \"must not\", \"mustn't've\": \"must not have\", \"needn't\": \"need not\", \n",
    "                       \"needn't've\": \"need not have\",\"o'clock\": \"of the clock\", \"oughtn't\": \"ought not\", \"oughtn't've\": \"ought not have\", \"shan't\": \"shall not\",\n",
    "                       \"sha'n't\": \"shall not\", \"shan't've\": \"shall not have\", \"she'd\": \"she would\", \"she'd've\": \"she would have\", \"she'll\": \"she will\", \n",
    "                       \"she'll've\": \"she will have\", \"she's\": \"she is\", \"should've\": \"should have\", \"shouldn't\": \"should not\", \"shouldn't've\": \"should not have\",\n",
    "                       \"so've\": \"so have\",\"so's\": \"so as\", \"this's\": \"this is\",\"that'd\": \"that would\", \"that'd've\": \"that would have\", \"that's\": \"that is\",\n",
    "                       \"there'd\": \"there would\", \"there'd've\": \"there would have\", \"there's\": \"there is\", \"here's\": \"here is\",\"they'd\": \"they would\",\n",
    "                       \"they'd've\": \"they would have\", \"they'll\": \"they will\", \"they'll've\": \"they will have\", \"they're\": \"they are\", \"they've\": \"they have\",\n",
    "                       \"to've\": \"to have\", \"wasn't\": \"was not\", \"we'd\": \"we would\", \"we'd've\": \"we would have\", \"we'll\": \"we will\", \"we'll've\": \"we will have\",\n",
    "                       \"we're\": \"we are\", \"we've\": \"we have\", \"weren't\": \"were not\", \"what'll\": \"what will\", \"what'll've\": \"what will have\", \n",
    "                       \"what're\": \"what are\",  \"what's\": \"what is\", \"what've\": \"what have\", \"when's\": \"when is\", \"when've\": \"when have\", \"where'd\": \"where did\",\n",
    "                       \"where's\": \"where is\", \"where've\": \"where have\", \"who'll\": \"who will\", \"who'll've\": \"who will have\", \"who's\": \"who is\", \n",
    "                       \"who've\": \"who have\", \"why's\": \"why is\", \"why've\": \"why have\", \"will've\": \"will have\", \"won't\": \"will not\", \"won't've\": \"will not have\", \n",
    "                       \"would've\": \"would have\", \"wouldn't\": \"would not\", \"wouldn't've\": \"would not have\", \"y'all\": \"you all\", \"y'all'd\": \"you all would\",\n",
    "                       \"y'all'd've\": \"you all would have\",\"y'all're\": \"you all are\",\"y'all've\": \"you all have\",\"you'd\": \"you would\", \"you'd've\": \"you would have\",\n",
    "                       \"you'll\": \"you will\", \"you'll've\": \"you will have\", \"you're\": \"you are\", \"you've\": \"you have\", 'u.s':'america', 'e.g':'for example'}\n",
    "\n",
    "punct = [',', '.', '\"', ':', ')', '(', '-', '!', '?', '|', ';', \"'\", '$', '&', '/', '[', ']', '>', '%', '=', '#', '*', '+', '\\\\', '•',  '~', '@', '£', \n",
    " '·', '_', '{', '}', '©', '^', '®', '`',  '<', '→', '°', '€', '™', '›',  '♥', '←', '×', '§', '″', '′', 'Â', '█', '½', 'à', '…', \n",
    " '“', '★', '”', '–', '●', 'â', '►', '−', '¢', '²', '¬', '░', '¶', '↑', '±', '¿', '▾', '═', '¦', '║', '―', '¥', '▓', '—', '‹', '─', \n",
    " '▒', '：', '¼', '⊕', '▼', '▪', '†', '■', '’', '▀', '¨', '▄', '♫', '☆', 'é', '¯', '♦', '¤', '▲', 'è', '¸', '¾', 'Ã', '⋅', '‘', '∞', \n",
    " '∙', '）', '↓', '、', '│', '（', '»', '，', '♪', '╩', '╚', '³', '・', '╦', '╣', '╔', '╗', '▬', '❤', 'ï', 'Ø', '¹', '≤', '‡', '√', ]\n",
    "\n",
    "punct_mapping = {\"‘\": \"'\", \"₹\": \"e\", \"´\": \"'\", \"°\": \"\", \"€\": \"e\", \"™\": \"tm\", \"√\": \" sqrt \", \"×\": \"x\", \"²\": \"2\", \"—\": \"-\", \"–\": \"-\", \"’\": \"'\", \"_\": \"-\",\n",
    "                 \"`\": \"'\", '“': '\"', '”': '\"', '“': '\"', \"£\": \"e\", '∞': 'infinity', 'θ': 'theta', '÷': '/', 'α': 'alpha', '•': '.', 'à': 'a', '−': '-', \n",
    "                 'β': 'beta', '∅': '', '³': '3', 'π': 'pi', '!':' '}\n",
    "\n",
    "mispell_dict = {'colour': 'color', 'centre': 'center', 'favourite': 'favorite', 'travelling': 'traveling', 'counselling': 'counseling', 'theatre': 'theater',\n",
    "                'cancelled': 'canceled', 'labour': 'labor', 'organisation': 'organization', 'wwii': 'world war 2', 'citicise': 'criticize', 'youtu ': 'youtube ',\n",
    "                'Qoura': 'Quora', 'sallary': 'salary', 'Whta': 'What', 'narcisist': 'narcissist', 'howdo': 'how do', 'whatare': 'what are', 'howcan': 'how can',\n",
    "                'howmuch': 'how much', 'howmany': 'how many', 'whydo': 'why do', 'doI': 'do I', 'theBest': 'the best', 'howdoes': 'how does', \n",
    "                'mastrubation': 'masturbation', 'mastrubate': 'masturbate', \"mastrubating\": 'masturbating', 'pennis': 'penis', 'Etherium': 'Ethereum', \n",
    "                'narcissit': 'narcissist', 'bigdata': 'big data', '2k17': '2017', '2k18': '2018', 'qouta': 'quota', 'exboyfriend': 'ex boyfriend', \n",
    "                'airhostess': 'air hostess', \"whst\": 'what', 'watsapp': 'whatsapp', 'demonitisation': 'demonetization', 'demonitization': 'demonetization',\n",
    "                'demonetisation': 'demonetization'}\n",
    "\n",
    "def clean_text(text):\n",
    "    '''Clean emoji, Make text lowercase, remove text in square brackets,remove links,remove punctuation\n",
    "    and remove words containing numbers.'''\n",
    "#     text = emoji.demojize(text)\n",
    "#     text = re.sub(r'\\:(.*?)\\:','',text)\n",
    "#     text = str(text).lower()    #Making Text Lowercase\n",
    "#     text = re.sub('\\[.*?\\]', '', text)\n",
    "    #The next 2 lines remove html text\n",
    "    text = BeautifulSoup(text, 'lxml').get_text()\n",
    "    text = re.sub('https?://\\S+|www\\.\\S+', '', text)\n",
    "    text = re.sub('<.*?>+', '', text)\n",
    "    text = re.sub('\\n', '', text)\n",
    "#     text = re.sub('\\w*\\d\\w*', '', text)\n",
    "    # replacing everything with space except (a-z, A-Z, 0-9, \"%\", \".\", \"&\", \",\", \"'\", \"?\", \"!\", \",\", \"'\", \";\", \"-\")\n",
    "    text = re.sub(r\"[^a-zA-Z0-9?.!,¿'%&,';-]+\", \" \", text)\n",
    "    return text\n",
    "\n",
    "def clean_contractions(text, mapping):\n",
    "    '''Clean contraction using contraction mapping'''    \n",
    "    specials = [\"’\", \"‘\", \"´\", \"`\"]\n",
    "    for s in specials:\n",
    "        text = text.replace(s, \"'\")\n",
    "    for word in mapping.keys():\n",
    "        if \"\"+word+\"\" in text:\n",
    "            text = text.replace(\"\"+word+\"\", \"\"+mapping[word]+\"\")\n",
    "    #Remove Punctuations\n",
    "    text = re.sub('[%s]' % re.escape(string.punctuation), '', text)\n",
    "    # creating a space between a word and the punctuation following it\n",
    "    # eg: \"he is a boy.\" => \"he is a boy .\"\n",
    "    text = re.sub(r\"([?.!,¿])\", r\" \\1 \", text)\n",
    "    text = re.sub(r'[\" \"]+', \" \", text)\n",
    "    return text\n",
    "\n",
    "def clean_special_chars(text, punct, mapping):\n",
    "    '''Cleans special characters present(if any)'''   \n",
    "    for p in mapping:\n",
    "        text = text.replace(p, mapping[p])\n",
    "    \n",
    "    for p in punct:\n",
    "        text = text.replace(p, f' {p} ')\n",
    "    \n",
    "    specials = {'\\u200b': ' ', '…': ' ... ', '\\ufeff': '', 'करना': '', 'है': ''}  \n",
    "    for s in specials:\n",
    "        text = text.replace(s, specials[s])\n",
    "    \n",
    "    return text\n",
    "\n",
    "def correct_spelling(x, dic):\n",
    "    '''Corrects common spelling errors'''   \n",
    "    for word in dic.keys():\n",
    "        x = x.replace(word, dic[word])\n",
    "    return x\n",
    "\n",
    "def remove_space(text):\n",
    "    '''Removes awkward spaces'''   \n",
    "    #Removes awkward spaces \n",
    "    text = text.strip()\n",
    "    text = text.split()\n",
    "    return \" \".join(text)\n",
    "\n",
    "def text_preprocessing_pipeline(text):\n",
    "    '''Cleaning and parsing the text.'''\n",
    "#     text = clean_contractions(text, contraction_mapping)\n",
    "    text = clean_text(text)\n",
    "#     text = clean_contractions(text, contraction_mapping)\n",
    "#     text = clean_special_chars(text, punct, punct_mapping)\n",
    "#     text = correct_spelling(text, mispell_dict)\n",
    "    text = remove_space(text)\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "4f78d7b6",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-01T11:04:16.297681Z",
     "iopub.status.busy": "2025-03-01T11:04:16.297403Z",
     "iopub.status.idle": "2025-03-01T11:04:19.430837Z",
     "shell.execute_reply": "2025-03-01T11:04:19.430156Z"
    },
    "papermill": {
     "duration": 3.147222,
     "end_time": "2025-03-01T11:04:19.432399",
     "exception": false,
     "start_time": "2025-03-01T11:04:16.285177",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-8-93bb6d8e489f>:51: MarkupResemblesLocatorWarning: The input looks more like a filename than markup. You may want to open this file and pass the filehandle into Beautiful Soup.\n",
      "  text = BeautifulSoup(text, 'lxml').get_text()\n"
     ]
    }
   ],
   "source": [
    "df['input'] = df['input'].apply(lambda x: text_preprocessing_pipeline(x))\n",
    "df['target'] = df['target'].apply(lambda x: text_preprocessing_pipeline(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "84905ecc",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-01T11:04:19.456811Z",
     "iopub.status.busy": "2025-03-01T11:04:19.456573Z",
     "iopub.status.idle": "2025-03-01T11:04:19.461065Z",
     "shell.execute_reply": "2025-03-01T11:04:19.460468Z"
    },
    "papermill": {
     "duration": 0.017315,
     "end_time": "2025-03-01T11:04:19.462149",
     "exception": false,
     "start_time": "2025-03-01T11:04:19.444834",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "df['input'] = df['input'].astype(str)\n",
    "df['target'] = df['target'].astype(str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "a85afa63",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-01T11:04:19.486199Z",
     "iopub.status.busy": "2025-03-01T11:04:19.485905Z",
     "iopub.status.idle": "2025-03-01T11:04:19.571277Z",
     "shell.execute_reply": "2025-03-01T11:04:19.570360Z"
    },
    "papermill": {
     "duration": 0.099487,
     "end_time": "2025-03-01T11:04:19.572818",
     "exception": false,
     "start_time": "2025-03-01T11:04:19.473331",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "2409bec1",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-01T11:04:19.596883Z",
     "iopub.status.busy": "2025-03-01T11:04:19.596595Z",
     "iopub.status.idle": "2025-03-01T11:04:19.599925Z",
     "shell.execute_reply": "2025-03-01T11:04:19.599097Z"
    },
    "papermill": {
     "duration": 0.016342,
     "end_time": "2025-03-01T11:04:19.601097",
     "exception": false,
     "start_time": "2025-03-01T11:04:19.584755",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# class TextDataset(Dataset):\n",
    "#     def __init__(self, tokenizer, texts, targets, max_length=256):\n",
    "#         self.tokenizer = tokenizer\n",
    "#         self.texts = texts\n",
    "#         self.targets = targets\n",
    "#         self.max_length = max_length\n",
    "\n",
    "#     def __len__(self):\n",
    "#         return len(self.texts)\n",
    "\n",
    "#     def __getitem__(self, idx):\n",
    "#         text = self.texts[idx]\n",
    "#         target = self.targets[idx]\n",
    "#         encodings = self.tokenizer(text, truncation=True, padding='max_length', max_length=self.max_length)\n",
    "#         target_encodings = self.tokenizer(target, truncation=True, padding='max_length', max_length=self.max_length)\n",
    "\n",
    "#         return {\n",
    "#             'input_ids': torch.tensor(encodings['input_ids'], dtype=torch.long),\n",
    "#             'attention_mask': torch.tensor(encodings['attention_mask'], dtype=torch.long),\n",
    "#             'labels': torch.tensor(target_encodings['input_ids'], dtype=torch.long)\n",
    "#         }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "f26b5d91",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-01T11:04:19.624357Z",
     "iopub.status.busy": "2025-03-01T11:04:19.624107Z",
     "iopub.status.idle": "2025-03-01T11:04:19.629708Z",
     "shell.execute_reply": "2025-03-01T11:04:19.629090Z"
    },
    "papermill": {
     "duration": 0.018457,
     "end_time": "2025-03-01T11:04:19.630920",
     "exception": false,
     "start_time": "2025-03-01T11:04:19.612463",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "from torch.utils.data import Dataset\n",
    "import torch\n",
    "\n",
    "class TextDataset(Dataset):\n",
    "    def __init__(self, tokenizer, dataset, max_length=256):\n",
    "        self.tokenizer = tokenizer\n",
    "        self.texts = dataset['input']\n",
    "        self.targets = dataset['target']\n",
    "        self.max_length = max_length\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.texts)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        text = self.texts[idx]\n",
    "        target = self.targets[idx]\n",
    "        encodings = self.tokenizer(text, truncation=True, padding='max_length', max_length=self.max_length)\n",
    "        target_encodings = self.tokenizer(target, truncation=True, padding='max_length', max_length=self.max_length)\n",
    "\n",
    "        return {\n",
    "            'input_ids': torch.tensor(encodings['input_ids'], dtype=torch.long),\n",
    "            'attention_mask': torch.tensor(encodings['attention_mask'], dtype=torch.long),\n",
    "            'labels': torch.tensor(target_encodings['input_ids'], dtype=torch.long)\n",
    "        }\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "c380e4cf",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-01T11:04:19.654383Z",
     "iopub.status.busy": "2025-03-01T11:04:19.654135Z",
     "iopub.status.idle": "2025-03-01T11:04:19.657462Z",
     "shell.execute_reply": "2025-03-01T11:04:19.656814Z"
    },
    "papermill": {
     "duration": 0.016244,
     "end_time": "2025-03-01T11:04:19.658690",
     "exception": false,
     "start_time": "2025-03-01T11:04:19.642446",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def test_train_split(dataset, test_ratio=0.1):\n",
    "  test_indices = np.random.rand(len(dataset)) < test_ratio\n",
    "  return dataset[~test_indices], dataset[test_indices]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "9fa8060a",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-01T11:04:19.682797Z",
     "iopub.status.busy": "2025-03-01T11:04:19.682348Z",
     "iopub.status.idle": "2025-03-01T11:04:19.692156Z",
     "shell.execute_reply": "2025-03-01T11:04:19.691311Z"
    },
    "papermill": {
     "duration": 0.023669,
     "end_time": "2025-03-01T11:04:19.693574",
     "exception": false,
     "start_time": "2025-03-01T11:04:19.669905",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9214 examples in training, 1066 examples in testing.\n"
     ]
    }
   ],
   "source": [
    "train_ds_pd, validation_ds_pd = test_train_split(df)\n",
    "print(\"{} examples in training, {} examples in testing.\".format(\n",
    "    len(train_ds_pd), len(validation_ds_pd)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "2cfebab1",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-01T11:04:19.717329Z",
     "iopub.status.busy": "2025-03-01T11:04:19.717077Z",
     "iopub.status.idle": "2025-03-01T11:04:19.722096Z",
     "shell.execute_reply": "2025-03-01T11:04:19.721469Z"
    },
    "papermill": {
     "duration": 0.018212,
     "end_time": "2025-03-01T11:04:19.723417",
     "exception": false,
     "start_time": "2025-03-01T11:04:19.705205",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "train_ds_pd = train_ds_pd.reset_index(drop=True)\n",
    "validation_ds_pd = validation_ds_pd.reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "3de7d516",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-01T11:04:19.748609Z",
     "iopub.status.busy": "2025-03-01T11:04:19.748356Z",
     "iopub.status.idle": "2025-03-01T11:04:19.751606Z",
     "shell.execute_reply": "2025-03-01T11:04:19.750950Z"
    },
    "papermill": {
     "duration": 0.017263,
     "end_time": "2025-03-01T11:04:19.752919",
     "exception": false,
     "start_time": "2025-03-01T11:04:19.735656",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "ce701b3c",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-01T11:04:19.778483Z",
     "iopub.status.busy": "2025-03-01T11:04:19.778124Z",
     "iopub.status.idle": "2025-03-01T11:04:19.781571Z",
     "shell.execute_reply": "2025-03-01T11:04:19.780859Z"
    },
    "papermill": {
     "duration": 0.017165,
     "end_time": "2025-03-01T11:04:19.782831",
     "exception": false,
     "start_time": "2025-03-01T11:04:19.765666",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# # Function to calculate cosine similarity between predicted and actual sentences\n",
    "# def calculate_cosine_similarity(pred_text, target_text, bert_model, bert_tokenizer, device=torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")):\n",
    "#     # Move model to GPU if available\n",
    "#     bert_model.to(device)\n",
    "\n",
    "#     # Tokenize and encode both texts, moving inputs to the GPU\n",
    "#     pred_inputs = bert_tokenizer(pred_text, return_tensors=\"pt\", truncation=True, padding=True).to(device)\n",
    "#     target_inputs = bert_tokenizer(target_text, return_tensors=\"pt\", truncation=True, padding=True).to(device)\n",
    "    \n",
    "#     # Get embeddings from BERT\n",
    "#     with torch.no_grad():\n",
    "#         with autocast(device_type=device.type):\n",
    "#             pred_embeddings = bert_model(**pred_inputs).last_hidden_state.mean(dim=1).to(device)\n",
    "#             target_embeddings = bert_model(**target_inputs).last_hidden_state.mean(dim=1).to(device)\n",
    "\n",
    "#     # Calculate cosine similarity\n",
    "#     similarity = cosine_similarity(pred_embeddings.cpu().numpy(), target_embeddings.cpu().numpy())[0][0]\n",
    "#     return similarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "0dfc9e3d",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-01T11:04:19.807000Z",
     "iopub.status.busy": "2025-03-01T11:04:19.806743Z",
     "iopub.status.idle": "2025-03-01T11:04:19.812977Z",
     "shell.execute_reply": "2025-03-01T11:04:19.812315Z"
    },
    "papermill": {
     "duration": 0.019585,
     "end_time": "2025-03-01T11:04:19.814141",
     "exception": false,
     "start_time": "2025-03-01T11:04:19.794556",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def calculate_cosine_similarity(pred_text, target_text, model, tokenizer, device, model_type=\"bart\"):\n",
    "    # Move model to GPU if available\n",
    "    model.to(device)\n",
    "\n",
    "    # Tokenize and encode both texts, moving inputs to the GPU\n",
    "    pred_inputs = tokenizer(pred_text, return_tensors=\"pt\", truncation=True, padding=True).to(device)\n",
    "    target_inputs = tokenizer(target_text, return_tensors=\"pt\", truncation=True, padding=True).to(device)\n",
    "\n",
    "    # Get embeddings based on the model type\n",
    "    with torch.no_grad():\n",
    "#         with torch.cuda.amp.autocast(enabled=True):  # Autocast for mixed precision training/inference\n",
    "        if model_type in [\"bart\", \"pegasus\", \"t5\"]:  # For seq2seq models like BART, Pegasus, T5\n",
    "            # Use encoder outputs\n",
    "            pred_embeddings = model.model.encoder(input_ids=pred_inputs.input_ids, attention_mask=pred_inputs.attention_mask).last_hidden_state.mean(dim=1).to(device)\n",
    "            target_embeddings = model.model.encoder(input_ids=target_inputs.input_ids, attention_mask=target_inputs.attention_mask).last_hidden_state.mean(dim=1).to(device)\n",
    "\n",
    "        elif model_type == \"llama\":  # For LLaMA models\n",
    "            pred_embeddings = model(**pred_inputs).hidden_states[-1].mean(dim=1).to(device)\n",
    "            target_embeddings = model(**target_inputs).hidden_states[-1].mean(dim=1).to(device)\n",
    "\n",
    "        else:  # For models like BERT, RoBERTa (directly exposing `last_hidden_state`)\n",
    "            pred_embeddings = model(**pred_inputs).last_hidden_state.mean(dim=1).to(device)\n",
    "            target_embeddings = model(**target_inputs).last_hidden_state.mean(dim=1).to(device)\n",
    "\n",
    "    # Calculate cosine similarity\n",
    "    similarity = cosine_similarity(pred_embeddings.cpu(), target_embeddings.cpu())[0].item()\n",
    "    return similarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "3cdfeb59",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-01T11:04:19.838705Z",
     "iopub.status.busy": "2025-03-01T11:04:19.838418Z",
     "iopub.status.idle": "2025-03-01T11:04:19.843091Z",
     "shell.execute_reply": "2025-03-01T11:04:19.842506Z"
    },
    "papermill": {
     "duration": 0.018376,
     "end_time": "2025-03-01T11:04:19.844405",
     "exception": false,
     "start_time": "2025-03-01T11:04:19.826029",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class EarlyStopping:\n",
    "    def __init__(self, patience=5, verbose=False, delta=0):\n",
    "        \"\"\"\n",
    "        EarlyStopping to stop training when a metric has stopped improving.\n",
    "\n",
    "        Args:\n",
    "            patience (int): How long to wait after last time validation loss improved.\n",
    "            verbose (bool): If True, prints a message for each validation loss improvement.\n",
    "            delta (float): Minimum change to qualify as an improvement.\n",
    "        \"\"\"\n",
    "        self.patience = patience\n",
    "        self.verbose = verbose\n",
    "        self.delta = delta\n",
    "        self.counter = 0\n",
    "        self.best_loss = np.inf\n",
    "        self.early_stop = False\n",
    "\n",
    "    def __call__(self, val_loss, model):\n",
    "        if val_loss < self.best_loss - self.delta:\n",
    "            self.best_loss = val_loss\n",
    "            self.counter = 0\n",
    "#             if self.verbose:\n",
    "#                 print(f'Validation loss improved to {val_loss:.4f}')\n",
    "#             torch.save(model.state_dict(), 'checkpoint.pt')\n",
    "        else:\n",
    "            self.counter += 1\n",
    "#             if self.verbose:\n",
    "#                 print(f'Validation loss did not improve. Patience: {self.patience}, Counter: {self.counter}')\n",
    "        \n",
    "        if self.counter >= self.patience:\n",
    "            self.early_stop = True\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "2bd2dcc7",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-01T11:04:19.867907Z",
     "iopub.status.busy": "2025-03-01T11:04:19.867693Z",
     "iopub.status.idle": "2025-03-01T11:04:19.870929Z",
     "shell.execute_reply": "2025-03-01T11:04:19.870325Z"
    },
    "papermill": {
     "duration": 0.01638,
     "end_time": "2025-03-01T11:04:19.872126",
     "exception": false,
     "start_time": "2025-03-01T11:04:19.855746",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# def train_bart_model(config, checkpoint_dir=None):\n",
    "#     tokenizer = BartTokenizer.from_pretrained('facebook/bart-base')\n",
    "#     model = BartForConditionalGeneration.from_pretrained('facebook/bart-base')\n",
    "#     device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "#     model.to(device)\n",
    "    \n",
    "    \n",
    "#     train_texts = train_ds_pd['input']\n",
    "#     train_labels = train_ds_pd['target']\n",
    "#     val_texts = validation_ds_pd['input']\n",
    "#     val_labels = validation_ds_pd['target']\n",
    "    \n",
    "#     train_dataset = TextDataset(tokenizer, train_texts, train_labels)\n",
    "#     val_dataset = TextDataset(tokenizer, val_texts, val_labels)\n",
    "    \n",
    "#     train_dataloader = DataLoader(train_dataset, batch_size=int(config['batch_size']), shuffle=True)\n",
    "#     val_dataloader = DataLoader(val_dataset, batch_size=int(config['batch_size']))\n",
    "\n",
    "#     optimizer = AdamW(model.parameters(), lr=config['lr'])\n",
    "\n",
    "#     # Training loop\n",
    "#     model.train()\n",
    "#     for epoch in range(int(config['epochs'])):\n",
    "#         epoch_loss = 0\n",
    "#         for batch in train_dataloader:\n",
    "#             optimizer.zero_grad()\n",
    "#             input_ids = batch['input_ids'].to(device)\n",
    "#             attention_mask = batch['attention_mask'].to(device)\n",
    "#             labels = batch['labels'].to(device)\n",
    "            \n",
    "#             outputs = model(input_ids=input_ids, attention_mask=attention_mask, labels=labels)\n",
    "#             loss = outputs.loss\n",
    "#             loss.backward()\n",
    "#             optimizer.step()\n",
    "#             epoch_loss += loss.item()\n",
    "        \n",
    "#         # Validation loop\n",
    "#         model.eval()\n",
    "#         val_loss = 0\n",
    "#         with torch.no_grad():\n",
    "#             for batch in val_dataloader:\n",
    "#                 input_ids = batch['input_ids'].to(device)\n",
    "#                 attention_mask = batch['attention_mask'].to(device)\n",
    "#                 labels = batch['labels'].to(device)\n",
    "#                 outputs = model(input_ids=input_ids, attention_mask=attention_mask, labels=labels)\n",
    "#                 val_loss += outputs.loss.item()\n",
    "\n",
    "#         # Report metrics to Ray Tune\n",
    "#         tune.report(train_loss=epoch_loss, val_loss=val_loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "16f44347",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-01T11:04:19.895454Z",
     "iopub.status.busy": "2025-03-01T11:04:19.895202Z",
     "iopub.status.idle": "2025-03-01T11:04:21.579726Z",
     "shell.execute_reply": "2025-03-01T11:04:21.578766Z"
    },
    "papermill": {
     "duration": 1.69815,
     "end_time": "2025-03-01T11:04:21.581626",
     "exception": false,
     "start_time": "2025-03-01T11:04:19.883476",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6d85e86fb2da4b769945d3496deedc50",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "vocab.json:   0%|          | 0.00/899k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "990f94a43cc54899b1ce9864629ac1af",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "merges.txt:   0%|          | 0.00/456k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "732af43242374bf48a2fc7a4ed596b62",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer.json:   0%|          | 0.00/1.36M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8843782d114c4062bdc2e30e5a8840ae",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/1.72k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "tokenizer = BartTokenizer.from_pretrained('facebook/bart-base')\n",
    "# bert_tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')\n",
    "# bert_tokenizer = DebertaV2Tokenizer.from_pretrained('microsoft/deberta-v3-base')\n",
    "# DebertaV2Model.from_pretrained('microsoft/deberta-v3-base')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "6e0a8f52",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-01T11:04:21.611966Z",
     "iopub.status.busy": "2025-03-01T11:04:21.611677Z",
     "iopub.status.idle": "2025-03-01T11:04:21.617611Z",
     "shell.execute_reply": "2025-03-01T11:04:21.616944Z"
    },
    "papermill": {
     "duration": 0.020632,
     "end_time": "2025-03-01T11:04:21.618844",
     "exception": false,
     "start_time": "2025-03-01T11:04:21.598212",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# # def train_bart_model_with_mixed_precision(config, checkpoint_dir=None):\n",
    "\n",
    "# # config, train_dataset, val_dataset, device\n",
    "# def train_model(config, train_dataset, val_dataset, device):\n",
    "#     # tokenizer = BartTokenizer.from_pretrained('facebook/bart-base')\n",
    "#     tokenizer = AutoTokenizer.from_pretrained(\"meta-llama/Meta-Llama-3-8B\")\n",
    "#     # model = BartForConditionalGeneration.from_pretrained('facebook/bart-base')\n",
    "#     model = AutoModelForCausalLM.from_pretrained(\"meta-llama/Meta-Llama-3-8B\")\n",
    "\n",
    "#     device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "#     model.to(device)\n",
    "    \n",
    "# #     train_texts = train_ds_pd['input']\n",
    "# #     train_labels = train_ds_pd['target']\n",
    "# #     val_texts = validation_ds_pd['input']\n",
    "# #     val_labels = validation_ds_pd['target']\n",
    "\n",
    "# #     train_dataset = TextDataset(tokenizer, train_texts, train_labels)\n",
    "# #     val_dataset = TextDataset(tokenizer, val_texts, val_labels)\n",
    "    \n",
    "#     train_loader = DataLoader(train_dataset, batch_size=int(config['batch_size']), shuffle=False)\n",
    "#     val_loader = DataLoader(val_dataset, batch_size=int(config['batch_size']), shuffle=False)\n",
    "\n",
    "#     optimizer = AdamW(model.parameters(), lr=config['lr'])\n",
    "#     scaler = GradScaler()  # Initialize the gradient scaler for mixed precision\n",
    "    \n",
    "#     scheduler = optim.lr_scheduler.ReduceLROnPlateau(optimizer, mode='min', factor=0.1, patience=2, verbose=True)\n",
    "    \n",
    "#     early_stopping = EarlyStopping(patience=3, verbose=True)\n",
    "\n",
    "#     # Training loop with mixed precision\n",
    "#     for epoch in range(int(config['epochs'])):\n",
    "#         model.train()\n",
    "        \n",
    "#         total_train_loss = 0.0\n",
    "        \n",
    "#         for batch in train_loader:\n",
    "            \n",
    "#             input_ids = batch['input_ids'].to(device)\n",
    "#             attention_mask = batch['attention_mask'].to(device)\n",
    "#             labels = batch['labels'].to(device)\n",
    "            \n",
    "#             optimizer.zero_grad()\n",
    "            \n",
    "#             with autocast(device_type=device.type):  # Use autocast for mixed precision\n",
    "#                 outputs = model(input_ids=input_ids, attention_mask=attention_mask, labels=labels)\n",
    "#                 loss = outputs.loss\n",
    "\n",
    "#             # Scale the loss and backpropagate\n",
    "#             scaler.scale(loss).backward()\n",
    "#             scaler.step(optimizer)\n",
    "#             scaler.update()\n",
    "\n",
    "#             total_train_loss += loss.item()\n",
    "            \n",
    "#         avg_train_loss = total_train_loss / len(train_loader)\n",
    "\n",
    "#         # Validation loop with mixed precision\n",
    "#         model.eval()\n",
    "        \n",
    "#         total_val_loss = 0.0\n",
    "#         val_similarity = 0.0\n",
    "#         num_val_samples = 0\n",
    "        \n",
    "#         with torch.no_grad():\n",
    "#             for batch in val_loader:\n",
    "#                 input_ids = batch['input_ids'].to(device)\n",
    "#                 attention_mask = batch['attention_mask'].to(device)\n",
    "#                 labels = batch['labels'].to(device)\n",
    "                \n",
    "#                 with autocast(device_type=device.type):\n",
    "#                     outputs = model(input_ids=input_ids, attention_mask=attention_mask, labels=labels)\n",
    "#                     loss = outputs.loss\n",
    "\n",
    "#                 preds = model.generate(input_ids=input_ids, attention_mask=attention_mask, max_length=512)\n",
    "#                 pred_texts = tokenizer.batch_decode(preds, skip_special_tokens=True)\n",
    "#                 target_texts = tokenizer.batch_decode(labels, skip_special_tokens=True)\n",
    "\n",
    "#                 for pred_text, target_text in zip(pred_texts, target_texts):\n",
    "#                     similarity = calculate_cosine_similarity(pred_text, target_text, model, tokenizer, device)\n",
    "#                     val_similarity += similarity\n",
    "#                     num_val_samples += 1\n",
    "\n",
    "#                 total_val_loss += loss.item()\n",
    "                \n",
    "#         avg_val_loss = total_val_loss / len(val_loader)\n",
    "# #         avg_val_similarity = val_similarity / len(val_loader)\n",
    "#         avg_val_similarity = val_similarity / num_val_samples\n",
    "        \n",
    "\n",
    "\n",
    "#         # Report both loss and similarity\n",
    "# #         tune.report(train_loss=avg_train_loss, val_loss=avg_val_loss, val_similarity=avg_val_similarity)\n",
    "        \n",
    "#         report({\n",
    "#             \"loss\": avg_val_loss,\n",
    "#             \"similarity\": avg_val_similarity,\n",
    "#             \"train_loss\": avg_train_loss,\n",
    "#             \"early_stopping_epoch\": epoch + 1,\n",
    "#         })\n",
    "        \n",
    "        \n",
    "#         # Learning rate scheduler step\n",
    "#         scheduler.step(avg_val_loss)\n",
    "        \n",
    "        \n",
    "#         early_stopping(avg_val_loss, model)\n",
    "#         if early_stopping.early_stop:\n",
    "# #             print(\"Early stopping\")\n",
    "#             break\n",
    "    \n",
    "#     return model\n",
    "    \n",
    "    \n",
    "# def train_fn(config):\n",
    "#     # Load your data here\n",
    "#     tokenizer = BartTokenizer.from_pretrained('facebook/bart-base')\n",
    "# #     bert_tokenizer = DebertaV2Tokenizer.from_pretrained('microsoft/deberta-v3-base')\n",
    "\n",
    "# #     train_dataset = DisasterDataset(train_ds_pd, tokenizer, max_len=192)\n",
    "# #     val_dataset = DisasterDataset(validation_ds_pd, tokenizer, max_len=192)\n",
    "\n",
    "#     train_dataset = TextDataset(tokenizer, train_ds_pd)\n",
    "#     val_dataset = TextDataset(tokenizer, validation_ds_pd)\n",
    "\n",
    "#     device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "#     train_model(config, train_dataset, val_dataset, device)\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "d4f2cb0e",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-01T11:04:21.643114Z",
     "iopub.status.busy": "2025-03-01T11:04:21.642854Z",
     "iopub.status.idle": "2025-03-01T11:04:21.646923Z",
     "shell.execute_reply": "2025-03-01T11:04:21.646136Z"
    },
    "papermill": {
     "duration": 0.017403,
     "end_time": "2025-03-01T11:04:21.648190",
     "exception": false,
     "start_time": "2025-03-01T11:04:21.630787",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# import torch\n",
    "# import torch.optim as optim\n",
    "# from torch.utils.data import DataLoader\n",
    "# from torch.optim import AdamW\n",
    "# from torch.cuda.amp import GradScaler, autocast\n",
    "# from transformers import AutoTokenizer, AutoModelForCausalLM\n",
    "\n",
    "# def train_model(config, train_dataset, val_dataset, device):\n",
    "#     \"\"\"\n",
    "#     Train the LLaMA 3 8B model using full fine-tuning with mixed precision.\n",
    "    \n",
    "#     Args:\n",
    "#         config (dict): Training configuration containing batch_size, lr, and epochs.\n",
    "#         train_dataset (Dataset): Training dataset.\n",
    "#         val_dataset (Dataset): Validation dataset.\n",
    "#         device (torch.device): CUDA or CPU device.\n",
    "        \n",
    "#     Returns:\n",
    "#         model: Trained model.\n",
    "#     \"\"\"\n",
    "\n",
    "#     # Load tokenizer and model\n",
    "#     model_name = \"meta-llama/Meta-Llama-3-8B\"\n",
    "#     tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "#     model = AutoModelForCausalLM.from_pretrained(model_name)\n",
    "\n",
    "#     model.to(device)\n",
    "\n",
    "#     # DataLoaders\n",
    "#     train_loader = DataLoader(train_dataset, batch_size=config['batch_size'], shuffle=True)\n",
    "#     val_loader = DataLoader(val_dataset, batch_size=config['batch_size'], shuffle=False)\n",
    "\n",
    "#     # Optimizer, LR Scheduler, and Mixed Precision\n",
    "#     optimizer = AdamW(model.parameters(), lr=config['lr'])\n",
    "#     scaler = GradScaler()\n",
    "#     scheduler = optim.lr_scheduler.ReduceLROnPlateau(optimizer, mode='min', factor=0.1, patience=2, verbose=True)\n",
    "\n",
    "#     early_stopping = EarlyStopping(patience=3, verbose=True)\n",
    "\n",
    "#     for epoch in range(config['epochs']):\n",
    "#         model.train()\n",
    "#         total_train_loss = 0.0\n",
    "\n",
    "#         for batch in train_loader:\n",
    "#             input_ids = batch['input_ids'].to(device)\n",
    "#             attention_mask = batch['attention_mask'].to(device)\n",
    "#             labels = batch['labels'].to(device)\n",
    "\n",
    "#             optimizer.zero_grad()\n",
    "\n",
    "#             with autocast(device_type=device.type):\n",
    "#                 outputs = model(input_ids=input_ids, attention_mask=attention_mask, labels=labels)\n",
    "#                 loss = outputs.loss\n",
    "\n",
    "#             scaler.scale(loss).backward()\n",
    "#             scaler.step(optimizer)\n",
    "#             scaler.update()\n",
    "\n",
    "#             total_train_loss += loss.item()\n",
    "\n",
    "#         avg_train_loss = total_train_loss / len(train_loader)\n",
    "\n",
    "#         # Validation\n",
    "#         model.eval()\n",
    "#         total_val_loss = 0.0\n",
    "#         val_similarity = 0.0\n",
    "#         num_val_samples = 0\n",
    "\n",
    "#         with torch.no_grad():\n",
    "#             for batch in val_loader:\n",
    "#                 input_ids = batch['input_ids'].to(device)\n",
    "#                 attention_mask = batch['attention_mask'].to(device)\n",
    "#                 labels = batch['labels'].to(device)\n",
    "\n",
    "#                 with autocast(device_type=device.type):\n",
    "#                     outputs = model(input_ids=input_ids, attention_mask=attention_mask, labels=labels)\n",
    "#                     loss = outputs.loss\n",
    "\n",
    "#                 preds = model.generate(input_ids=input_ids, attention_mask=attention_mask, max_length=512)\n",
    "#                 pred_texts = tokenizer.batch_decode(preds, skip_special_tokens=True)\n",
    "#                 target_texts = tokenizer.batch_decode(labels, skip_special_tokens=True)\n",
    "\n",
    "#                 for pred_text, target_text in zip(pred_texts, target_texts):\n",
    "#                     similarity = calculate_cosine_similarity(pred_text, target_text, model, tokenizer, device)\n",
    "#                     val_similarity += similarity\n",
    "#                     num_val_samples += 1\n",
    "\n",
    "#                 total_val_loss += loss.item()\n",
    "\n",
    "#         avg_val_loss = total_val_loss / len(val_loader)\n",
    "#         avg_val_similarity = val_similarity / num_val_samples\n",
    "\n",
    "#         # Logging metrics\n",
    "#         report({\n",
    "#             \"loss\": avg_val_loss,\n",
    "#             \"similarity\": avg_val_similarity,\n",
    "#             \"train_loss\": avg_train_loss,\n",
    "#             \"early_stopping_epoch\": epoch + 1,\n",
    "#         })\n",
    "\n",
    "#         # Learning rate scheduling & early stopping\n",
    "#         scheduler.step(avg_val_loss)\n",
    "#         early_stopping(avg_val_loss, model)\n",
    "\n",
    "#         if early_stopping.early_stop:\n",
    "#             print(\"Early stopping triggered.\")\n",
    "#             break\n",
    "\n",
    "#     return model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "08a4eed5",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-01T11:04:21.672424Z",
     "iopub.status.busy": "2025-03-01T11:04:21.672167Z",
     "iopub.status.idle": "2025-03-01T11:04:21.675129Z",
     "shell.execute_reply": "2025-03-01T11:04:21.674532Z"
    },
    "papermill": {
     "duration": 0.01617,
     "end_time": "2025-03-01T11:04:21.676190",
     "exception": false,
     "start_time": "2025-03-01T11:04:21.660020",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# # Hyperparameter tuning function with Ray Tune\n",
    "# def tune_model_with_mixed_precision():\n",
    "#     search_space = {\n",
    "#         \"lr\": tune.loguniform(1e-7, 1e-2),\n",
    "#         \"batch_size\": tune.choice([8, 16, 32]),\n",
    "#         \"epochs\": tune.choice([3, 5, 7, 10, 12, 15, 20])\n",
    "#     }\n",
    "    \n",
    "#     reporter = JupyterNotebookReporter(\n",
    "#         metric_columns=[\"loss\", \"training_iteration\", \"train_loss\", \"similarity\", \"early_stopping_epoch\"],\n",
    "#         print_intermediate_tables=False,\n",
    "#     )\n",
    "    \n",
    "#     optuna_search = OptunaSearch(\n",
    "#         metric=\"loss\",\n",
    "#         mode=\"min\"\n",
    "#     )\n",
    "    \n",
    "    \n",
    "\n",
    "#     scheduler = ASHAScheduler(\n",
    "#         metric='loss',\n",
    "#         mode='min',\n",
    "#         max_t=22,\n",
    "#         grace_period=3,\n",
    "#         reduction_factor=2\n",
    "#     )\n",
    "\n",
    "\n",
    "\n",
    "#     analysis = tune.run(\n",
    "#         train_fn,\n",
    "#         config=search_space,\n",
    "#         num_samples=30,\n",
    "#         resources_per_trial={\"cpu\": 2, \"gpu\": 1},\n",
    "#         progress_reporter=reporter,\n",
    "#         search_alg=optuna_search\n",
    "#     )\n",
    "\n",
    "#     print(\"Best hyperparameters found:\", analysis.best_config)\n",
    "    \n",
    "#     best_trial = result.get_best_trial(\"accuracy\", \"max\", \"last\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "1101a33d",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-01T11:04:21.705386Z",
     "iopub.status.busy": "2025-03-01T11:04:21.705082Z",
     "iopub.status.idle": "2025-03-01T11:04:21.707819Z",
     "shell.execute_reply": "2025-03-01T11:04:21.707360Z"
    },
    "papermill": {
     "duration": 0.019883,
     "end_time": "2025-03-01T11:04:21.709056",
     "exception": false,
     "start_time": "2025-03-01T11:04:21.689173",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# ray.init(ignore_reinit_error=True)\n",
    "# tune_model_with_mixed_precision()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "0610e127",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-01T11:04:21.743370Z",
     "iopub.status.busy": "2025-03-01T11:04:21.742895Z",
     "iopub.status.idle": "2025-03-01T11:04:21.747132Z",
     "shell.execute_reply": "2025-03-01T11:04:21.746326Z"
    },
    "papermill": {
     "duration": 0.025815,
     "end_time": "2025-03-01T11:04:21.748759",
     "exception": false,
     "start_time": "2025-03-01T11:04:21.722944",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# # search_space = {\n",
    "# #     \"lr\": tune.loguniform(1e-7, 1e-2),\n",
    "# #     \"batch_size\": tune.choice([8, 16, 32]),\n",
    "# #     \"epochs\": tune.choice([3, 5, 7, 10, 12, 15, 20])\n",
    "# # }\n",
    "\n",
    "# search_space = {\n",
    "#     \"lr\": tune.choice([1e-7, 2e-7, 5e-7, 1e-6, 5e-6, 1e-5, 2e-5]),\n",
    "#     \"batch_size\": tune.choice([4, 8]),\n",
    "#     \"epochs\": tune.choice([5, 10, 15])\n",
    "# }\n",
    "\n",
    "\n",
    "# # reporter = CLIReporter(\n",
    "# #     metric_columns=[\"loss\", \"training_iteration\", \"train_loss\", \"similarity\", \"early_stopping_epoch\"],\n",
    "# #     print_intermediate_tables=True,\n",
    "# # )\n",
    "    \n",
    "# reporter = JupyterNotebookReporter(\n",
    "#     metric_columns=[\"loss\", \"training_iteration\", \"train_loss\", \"similarity\", \"early_stopping_epoch\"],\n",
    "#     print_intermediate_tables=False,\n",
    "# )\n",
    "    \n",
    "# optuna_search = OptunaSearch(\n",
    "#     metric=\"loss\",\n",
    "#     mode=\"min\"\n",
    "# )\n",
    "    \n",
    "    \n",
    "\n",
    "# scheduler = ASHAScheduler(\n",
    "#     metric='loss',\n",
    "#     mode='min',\n",
    "#     max_t=16,\n",
    "#     grace_period=3,\n",
    "#     reduction_factor=2\n",
    "# )\n",
    "\n",
    "\n",
    "\n",
    "# analysis = tune.run(\n",
    "#     train_fn,\n",
    "#     config=search_space,\n",
    "#     num_samples=15,\n",
    "#     resources_per_trial={\"cpu\": 2, \"gpu\": 1},\n",
    "#     progress_reporter=reporter,\n",
    "#     search_alg=optuna_search\n",
    "# )\n",
    "\n",
    "# # print(\"Best hyperparameters found:\", analysis.best_config)\n",
    "    \n",
    "# best_trial = analysis.get_best_trial(\"loss\", \"min\", \"last\")\n",
    "\n",
    "# print(f\"Best trial config: {best_trial.config}\")\n",
    "# print(f\"Best trial final validation loss: {best_trial.last_result['loss']}\")\n",
    "# print(f\"Best trial final training loss: {best_trial.last_result['train_loss']}\")\n",
    "# print(f\"Best trial final cosine similarity score: {best_trial.last_result['similarity']}\")\n",
    "# print(f\"Best trial final Early Stopping Epoch: {best_trial.last_result['early_stopping_epoch']}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "f9e8b96f",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-01T11:04:21.788600Z",
     "iopub.status.busy": "2025-03-01T11:04:21.788346Z",
     "iopub.status.idle": "2025-03-01T11:04:21.799173Z",
     "shell.execute_reply": "2025-03-01T11:04:21.798589Z"
    },
    "papermill": {
     "duration": 0.030669,
     "end_time": "2025-03-01T11:04:21.800474",
     "exception": false,
     "start_time": "2025-03-01T11:04:21.769805",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Function to train the model with best hyperparameters\n",
    "def train_best_model(config, device, train_dataset = train_ds_pd, val_dataset = validation_ds_pd):\n",
    "    \n",
    "    print(f\"\"\"\n",
    "    Tuning Model with:\n",
    "    {config}\n",
    "    \"\"\")\n",
    "    \n",
    "    best_val_loss = float(\"inf\")\n",
    "    best_model_path = None\n",
    "    epochs_since_improvement = 0\n",
    "    \n",
    "    tokenizer = BartTokenizer.from_pretrained('facebook/bart-base')\n",
    "    model = BartForConditionalGeneration.from_pretrained('facebook/bart-base')\n",
    "\n",
    "    model.to(device)\n",
    "    \n",
    "    train_dataset = TextDataset(tokenizer, train_dataset)\n",
    "    val_dataset = TextDataset(tokenizer, val_dataset)\n",
    "    \n",
    "    train_loader = DataLoader(train_dataset, batch_size=int(config['batch_size']), shuffle=False)\n",
    "    val_loader = DataLoader(val_dataset, batch_size=int(config['batch_size']), shuffle=False)\n",
    "\n",
    "    optimizer = AdamW(model.parameters(), lr=config['lr'])\n",
    "    scaler = GradScaler()  # Mixed precision scaler\n",
    "    \n",
    "    scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer, mode='min', factor=0.1, patience=2, verbose=True)\n",
    "    patience=5\n",
    "    early_stopping = EarlyStopping(patience, verbose=True)\n",
    "\n",
    "    for epoch in range(int(config['epochs'])+patience+1):\n",
    "        model.train()\n",
    "        total_train_loss = 0.0\n",
    "        \n",
    "        for batch in train_loader:\n",
    "            input_ids = batch['input_ids'].to(device)\n",
    "            attention_mask = batch['attention_mask'].to(device)\n",
    "            labels = batch['labels'].to(device)\n",
    "            \n",
    "            optimizer.zero_grad()\n",
    "            \n",
    "            with autocast(device_type=device.type):\n",
    "                outputs = model(input_ids=input_ids, attention_mask=attention_mask, labels=labels)\n",
    "                loss = outputs.loss\n",
    "\n",
    "            scaler.scale(loss).backward()\n",
    "            scaler.step(optimizer)\n",
    "            scaler.update()\n",
    "\n",
    "            total_train_loss += loss.item()\n",
    "            \n",
    "        avg_train_loss = total_train_loss / len(train_loader)\n",
    "\n",
    "        model.eval()\n",
    "        total_val_loss = 0.0\n",
    "        val_similarity = 0.0\n",
    "        num_val_samples = 0\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            for batch in val_loader:\n",
    "                input_ids = batch['input_ids'].to(device)\n",
    "                attention_mask = batch['attention_mask'].to(device)\n",
    "                labels = batch['labels'].to(device)\n",
    "                \n",
    "                with autocast(device_type=device.type):\n",
    "                    outputs = model(input_ids=input_ids, attention_mask=attention_mask, labels=labels)\n",
    "                    loss = outputs.loss\n",
    "\n",
    "                preds = model.generate(input_ids=input_ids, attention_mask=attention_mask, max_length=512)\n",
    "                pred_texts = tokenizer.batch_decode(preds, skip_special_tokens=True)\n",
    "                target_texts = tokenizer.batch_decode(labels, skip_special_tokens=True)\n",
    "\n",
    "                for pred_text, target_text in zip(pred_texts, target_texts):\n",
    "                    similarity = calculate_cosine_similarity(pred_text, target_text, model, tokenizer, device)\n",
    "                    val_similarity += similarity\n",
    "                    num_val_samples += 1\n",
    "\n",
    "                total_val_loss += loss.item()\n",
    "                \n",
    "        avg_val_loss = total_val_loss / len(val_loader)\n",
    "#         avg_val_similarity = val_similarity / len(val_loader)\n",
    "        avg_val_similarity = val_similarity / num_val_samples\n",
    "        \n",
    "        checkpoint_path = f\"/kaggle/working/best_checkpoint.pt\"\n",
    "        \n",
    "        scheduler.step(avg_val_loss)\n",
    "        \n",
    "        if avg_val_loss < best_val_loss:\n",
    "            best_val_loss = avg_val_loss\n",
    "            epochs_since_improvement = 0\n",
    "            best_model_path = checkpoint_path\n",
    "            # Save the model checkpoint with the best validation loss\n",
    "#             checkpoint_path = f\"/kaggle/working/best_checkpoint.pt\"\n",
    "#             torch.save(model.state_dict(), checkpoint_path)\n",
    "            torch.save({\n",
    "                'model_state_dict': model.state_dict(),\n",
    "                'config': config  # Save configuration\n",
    "            }, checkpoint_path)\n",
    "    \n",
    "        else:\n",
    "            epochs_since_improvement += 1\n",
    "\n",
    "        early_stopping(avg_val_loss, model)\n",
    "        if early_stopping.early_stop:\n",
    "            print(f\"Early stopping at epoch {epoch+1}\")\n",
    "            print(f\"Best Model Epoch Saved: {epoch - patience+1}\")\n",
    "#             print(\"Early stopping\")\n",
    "            break\n",
    "\n",
    "        print(f\"\"\"\n",
    "        Validation Loss: {avg_val_loss},\n",
    "        Training Loss: {avg_train_loss},\n",
    "        Cosine Similarity: {avg_val_similarity},\n",
    "        Epochs: {epoch+1}\n",
    "        \"\"\")\n",
    "            \n",
    "    print(f\"Best Validation Loss: {best_val_loss}\")\n",
    "\n",
    "    # Save the model\n",
    "#     model.save_pretrained('best_model')\n",
    "#     tokenizer.save_pretrained('best_model_tokenizer')\n",
    "\n",
    "    return model, best_model_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "ff4286e3",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-01T11:04:21.825035Z",
     "iopub.status.busy": "2025-03-01T11:04:21.824766Z",
     "iopub.status.idle": "2025-03-01T13:11:43.034502Z",
     "shell.execute_reply": "2025-03-01T13:11:43.033550Z"
    },
    "papermill": {
     "duration": 7641.236233,
     "end_time": "2025-03-01T13:11:43.048910",
     "exception": false,
     "start_time": "2025-03-01T11:04:21.812677",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "    Tuning Model with:\n",
      "    {'lr': 1e-06, 'batch_size': 8, 'epochs': 15}\n",
      "    \n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "549e63ee12e4400aba6a5bf33b1faab7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors:   0%|          | 0.00/558M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Asking to truncate to max_length but no maximum length is provided and the model has no predefined maximum length. Default to no truncation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "        Validation Loss: 2.2676671476506476,\n",
      "        Training Loss: 6.640102089486188,\n",
      "        Cosine Similarity: 0.9097542115268743,\n",
      "        Epochs: 1\n",
      "        \n",
      "\n",
      "        Validation Loss: 0.5576981177080923,\n",
      "        Training Loss: 1.7225606621036098,\n",
      "        Cosine Similarity: 0.9196197973742494,\n",
      "        Epochs: 2\n",
      "        \n",
      "\n",
      "        Validation Loss: 0.1862004178562271,\n",
      "        Training Loss: 0.503743706167572,\n",
      "        Cosine Similarity: 0.9296142846960959,\n",
      "        Epochs: 3\n",
      "        \n",
      "\n",
      "        Validation Loss: 0.10474627253724568,\n",
      "        Training Loss: 0.21226360940555525,\n",
      "        Cosine Similarity: 0.9390722166530187,\n",
      "        Epochs: 4\n",
      "        \n",
      "\n",
      "        Validation Loss: 0.07582745277114324,\n",
      "        Training Loss: 0.12700913608164732,\n",
      "        Cosine Similarity: 0.9444924544885503,\n",
      "        Epochs: 5\n",
      "        \n",
      "\n",
      "        Validation Loss: 0.062337606262638054,\n",
      "        Training Loss: 0.09183506160398894,\n",
      "        Cosine Similarity: 0.9487238854002102,\n",
      "        Epochs: 6\n",
      "        \n",
      "\n",
      "        Validation Loss: 0.05474197110439192,\n",
      "        Training Loss: 0.07340555180659673,\n",
      "        Cosine Similarity: 0.9516056570841268,\n",
      "        Epochs: 7\n",
      "        \n",
      "\n",
      "        Validation Loss: 0.05002848124270564,\n",
      "        Training Loss: 0.06269769896688457,\n",
      "        Cosine Similarity: 0.9548437830766638,\n",
      "        Epochs: 8\n",
      "        \n",
      "\n",
      "        Validation Loss: 0.0462644694185357,\n",
      "        Training Loss: 0.05565430901373879,\n",
      "        Cosine Similarity: 0.9568136423322989,\n",
      "        Epochs: 9\n",
      "        \n",
      "\n",
      "        Validation Loss: 0.04397038956965083,\n",
      "        Training Loss: 0.0510323428991089,\n",
      "        Cosine Similarity: 0.9604996674839149,\n",
      "        Epochs: 10\n",
      "        \n",
      "\n",
      "        Validation Loss: 0.04204497403993424,\n",
      "        Training Loss: 0.04763003879371455,\n",
      "        Cosine Similarity: 0.961522110910845,\n",
      "        Epochs: 11\n",
      "        \n",
      "\n",
      "        Validation Loss: 0.04032436709628621,\n",
      "        Training Loss: 0.04474356746181406,\n",
      "        Cosine Similarity: 0.963009077880888,\n",
      "        Epochs: 12\n",
      "        \n",
      "\n",
      "        Validation Loss: 0.039231790354781186,\n",
      "        Training Loss: 0.0420520808543693,\n",
      "        Cosine Similarity: 0.9641815386502872,\n",
      "        Epochs: 13\n",
      "        \n",
      "\n",
      "        Validation Loss: 0.03817443144785713,\n",
      "        Training Loss: 0.04020669875040363,\n",
      "        Cosine Similarity: 0.9658133331092169,\n",
      "        Epochs: 14\n",
      "        \n",
      "\n",
      "        Validation Loss: 0.03740464947047407,\n",
      "        Training Loss: 0.038358576504429545,\n",
      "        Cosine Similarity: 0.9665331085112931,\n",
      "        Epochs: 15\n",
      "        \n",
      "\n",
      "        Validation Loss: 0.036350485385715295,\n",
      "        Training Loss: 0.03684996029197565,\n",
      "        Cosine Similarity: 0.9676786501233171,\n",
      "        Epochs: 16\n",
      "        \n",
      "\n",
      "        Validation Loss: 0.03531886644856031,\n",
      "        Training Loss: 0.035334367504522866,\n",
      "        Cosine Similarity: 0.9686005837362658,\n",
      "        Epochs: 17\n",
      "        \n",
      "\n",
      "        Validation Loss: 0.034681001434853274,\n",
      "        Training Loss: 0.034570619540621315,\n",
      "        Cosine Similarity: 0.9692011496810483,\n",
      "        Epochs: 18\n",
      "        \n",
      "\n",
      "        Validation Loss: 0.03411651899996422,\n",
      "        Training Loss: 0.03320869630048643,\n",
      "        Cosine Similarity: 0.9705361413016328,\n",
      "        Epochs: 19\n",
      "        \n",
      "\n",
      "        Validation Loss: 0.03383556748879379,\n",
      "        Training Loss: 0.032274639866449836,\n",
      "        Cosine Similarity: 0.9707196905621892,\n",
      "        Epochs: 20\n",
      "        \n",
      "\n",
      "        Validation Loss: 0.0331675251772099,\n",
      "        Training Loss: 0.03126209694063517,\n",
      "        Cosine Similarity: 0.9711341765092417,\n",
      "        Epochs: 21\n",
      "        \n",
      "Best Validation Loss: 0.0331675251772099\n"
     ]
    }
   ],
   "source": [
    "# model_path = 'best_model'\n",
    "# best_config = analysis.best_config\n",
    "\n",
    "# best_config = best_trial.config\n",
    "\n",
    "default_config = {'lr': 1e-06, 'batch_size': 8, 'epochs': 15}\n",
    "\n",
    "# best_config = best_trial.config\n",
    "\n",
    "try:\n",
    "    best_trial = analysis.get_best_trial(\"loss\", \"min\", \"last\")\n",
    "except NameError:\n",
    "    best_trial = None  # Ensure best_trial is always defined\n",
    "\n",
    "# Check if best_trial exists and has a valid config, otherwise use default\n",
    "if best_trial and hasattr(best_trial, \"config\") and best_trial.config:\n",
    "    best_config = best_trial.config\n",
    "else:\n",
    "    best_config = default_config\n",
    "    \n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "\n",
    "best_model, best_model_path = train_best_model(best_config, device, train_ds_pd, validation_ds_pd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "aa43cba0",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-01T13:11:43.077388Z",
     "iopub.status.busy": "2025-03-01T13:11:43.077028Z",
     "iopub.status.idle": "2025-03-01T13:11:43.883714Z",
     "shell.execute_reply": "2025-03-01T13:11:43.882739Z"
    },
    "papermill": {
     "duration": 0.822553,
     "end_time": "2025-03-01T13:11:43.885040",
     "exception": false,
     "start_time": "2025-03-01T13:11:43.062487",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best model saved at: /kaggle/working/final_best_model.pt\n"
     ]
    }
   ],
   "source": [
    "final_model_path = \"/kaggle/working/final_best_model.pt\"\n",
    "# torch.save(best_model.state_dict(), final_model_path)\n",
    "torch.save({'model_state_dict': best_model.state_dict(),'config': best_config}, final_model_path)\n",
    "\n",
    "print(f\"Best model saved at: {final_model_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "e9930918",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-01T13:11:43.912331Z",
     "iopub.status.busy": "2025-03-01T13:11:43.912051Z",
     "iopub.status.idle": "2025-03-01T13:11:46.161666Z",
     "shell.execute_reply": "2025-03-01T13:11:46.160906Z"
    },
    "papermill": {
     "duration": 2.264264,
     "end_time": "2025-03-01T13:11:46.162887",
     "exception": false,
     "start_time": "2025-03-01T13:11:43.898623",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-31-fdf5a391eb5e>:6: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  checkpoint = torch.load(final_model_path)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded model from /kaggle/working/final_best_model.pt for inference.\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "# Load the best model\n",
    "final_model_path = \"/kaggle/working/final_best_model.pt\"\n",
    "# final_model_path = \"/kaggle/input/tachygraphy-lv2-emotion-moodtags-v1/transformers/default/1/final_best_model.pt\"\n",
    "\n",
    "\n",
    "checkpoint = torch.load(final_model_path)\n",
    "# config = checkpoint['config']\n",
    "\n",
    "# loaded_model = SentimentModel(\n",
    "#     roberta_model=RobertaModel.from_pretrained(\"roberta-base\"),\n",
    "#     n_classes=3,\n",
    "#     dropout_rate=config[\"dropout_rate\"]\n",
    "# )\n",
    "# loaded_model = DisasterModel(\n",
    "#     roberta_model=DebertaV2Model.from_pretrained('microsoft/deberta-v3-base'),\n",
    "#     n_classes=2,\n",
    "#     dropout_rate=config[\"dropout_rate\"]\n",
    "# )\n",
    "loaded_model = BartForConditionalGeneration.from_pretrained('facebook/bart-base')\n",
    "loaded_model.load_state_dict(checkpoint['model_state_dict'])\n",
    "loaded_model = loaded_model.to(device)\n",
    "loaded_model.eval()\n",
    "\n",
    "print(f\"Loaded model from {final_model_path} for inference.\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "311c3808",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-01T13:11:46.190071Z",
     "iopub.status.busy": "2025-03-01T13:11:46.189843Z",
     "iopub.status.idle": "2025-03-01T13:11:46.192849Z",
     "shell.execute_reply": "2025-03-01T13:11:46.192203Z"
    },
    "papermill": {
     "duration": 0.0176,
     "end_time": "2025-03-01T13:11:46.193970",
     "exception": false,
     "start_time": "2025-03-01T13:11:46.176370",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# def predict(model, tokenizer, input_texts, device):\n",
    "# #     model = BartForConditionalGeneration.from_pretrained('facebook/bart-base')\n",
    "# #     model.load_state_dict(torch.load(model_path)['model_state_dict'])\n",
    "#     model.to(device)\n",
    "# #     model.eval()\n",
    "\n",
    "#     predictions = []\n",
    "#     with torch.no_grad():\n",
    "#         for text in input_texts:\n",
    "#             encodings = tokenizer(text, return_tensors='pt', truncation=True, padding='max_length', max_length=256).to(device)\n",
    "#             input_ids = encodings['input_ids']\n",
    "#             attention_mask = encodings['attention_mask']\n",
    "            \n",
    "#             preds = model.generate(input_ids=input_ids, attention_mask=attention_mask, max_length=256)\n",
    "#             pred_text = tokenizer.decode(preds[0], skip_special_tokens=True)\n",
    "#             predictions.append(pred_text)\n",
    "    \n",
    "#     return predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "0596fdca",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-01T13:11:46.224066Z",
     "iopub.status.busy": "2025-03-01T13:11:46.223850Z",
     "iopub.status.idle": "2025-03-01T13:11:46.226776Z",
     "shell.execute_reply": "2025-03-01T13:11:46.226140Z"
    },
    "papermill": {
     "duration": 0.019581,
     "end_time": "2025-03-01T13:11:46.227898",
     "exception": false,
     "start_time": "2025-03-01T13:11:46.208317",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# # Predict function for random input\n",
    "# def predict_on_random_input(model, tokenizer, input_text):\n",
    "#     model.eval()\n",
    "#     device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "    \n",
    "#     inputs = tokenizer(input_text, return_tensors=\"pt\", truncation=True, padding=True).to(device)\n",
    "    \n",
    "#     with torch.no_grad():\n",
    "#         preds = model.generate(input_ids=inputs['input_ids'], attention_mask=inputs['attention_mask'], max_length=128)\n",
    "    \n",
    "#     pred_text = tokenizer.decode(preds[0], skip_special_tokens=True)\n",
    "#     return pred_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "a1342a74",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-01T13:11:46.255078Z",
     "iopub.status.busy": "2025-03-01T13:11:46.254782Z",
     "iopub.status.idle": "2025-03-01T13:11:46.259588Z",
     "shell.execute_reply": "2025-03-01T13:11:46.258861Z"
    },
    "papermill": {
     "duration": 0.020059,
     "end_time": "2025-03-01T13:11:46.260868",
     "exception": false,
     "start_time": "2025-03-01T13:11:46.240809",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def predict(model, tokenizer, input_texts, device):\n",
    "#     model = BartForConditionalGeneration.from_pretrained('facebook/bart-base')\n",
    "#     model.load_state_dict(torch.load(model_path)['model_state_dict'])\n",
    "    model.to(device)\n",
    "#     model.eval()\n",
    "\n",
    "    predictions = []\n",
    "    with torch.no_grad():\n",
    "#         for text in input_texts:\n",
    "        text = input_texts\n",
    "        encodings = tokenizer(text, return_tensors='pt', truncation=True, padding='max_length', max_length=256).to(device)\n",
    "        input_ids = encodings['input_ids']\n",
    "        attention_mask = encodings['attention_mask']\n",
    "            \n",
    "        preds = model.generate(input_ids=input_ids, attention_mask=attention_mask, max_length=512)\n",
    "        pred_text = tokenizer.decode(preds[0], skip_special_tokens=True)\n",
    "        predictions.append(pred_text)\n",
    "    \n",
    "    return predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "4b2ba2bc",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-01T13:11:46.289128Z",
     "iopub.status.busy": "2025-03-01T13:11:46.288819Z",
     "iopub.status.idle": "2025-03-01T13:11:46.429471Z",
     "shell.execute_reply": "2025-03-01T13:11:46.428675Z"
    },
    "papermill": {
     "duration": 0.155998,
     "end_time": "2025-03-01T13:11:46.430795",
     "exception": false,
     "start_time": "2025-03-01T13:11:46.274797",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input: pls hlp, idk wht 2 do\n",
      "Predicted Meaning: [\"Please help, I don't know what to do.\"]\n"
     ]
    }
   ],
   "source": [
    "# Test prediction on random input\n",
    "random_input = \"pls hlp, idk wht 2 do\"\n",
    "predicted_text = predict(loaded_model, tokenizer, random_input, device)\n",
    "print(f\"Input: {random_input}\")\n",
    "print(f\"Predicted Meaning: {predicted_text}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "231c5002",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-01T13:11:46.459632Z",
     "iopub.status.busy": "2025-03-01T13:11:46.459363Z",
     "iopub.status.idle": "2025-03-01T13:11:46.597615Z",
     "shell.execute_reply": "2025-03-01T13:11:46.596819Z"
    },
    "papermill": {
     "duration": 0.15413,
     "end_time": "2025-03-01T13:11:46.598916",
     "exception": false,
     "start_time": "2025-03-01T13:11:46.444786",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input: i don8 no fr y hes soooo sad\n",
      "Predicted Meaning: [\"i don't know why he's so sad.\"]\n"
     ]
    }
   ],
   "source": [
    "# Test prediction on random input\n",
    "random_input = \"i don8 no fr y hes soooo sad\"\n",
    "predicted_text = predict(loaded_model, tokenizer, random_input, device)\n",
    "print(f\"Input: {random_input}\")\n",
    "print(f\"Predicted Meaning: {predicted_text}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "835bfa10",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-01T13:11:46.626898Z",
     "iopub.status.busy": "2025-03-01T13:11:46.626635Z",
     "iopub.status.idle": "2025-03-01T13:11:46.770628Z",
     "shell.execute_reply": "2025-03-01T13:11:46.769636Z"
    },
    "papermill": {
     "duration": 0.159293,
     "end_time": "2025-03-01T13:11:46.771989",
     "exception": false,
     "start_time": "2025-03-01T13:11:46.612696",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input: hey! how are you, wanna ply valo toni8?\n",
      "Predicted Meaning: ['Hey! how are you, want to ply valo tonight?']\n"
     ]
    }
   ],
   "source": [
    "random_input = \"hey! how are you, wanna ply valo toni8?\"\n",
    "predicted_text = predict(loaded_model, tokenizer, random_input, device)\n",
    "print(f\"Input: {random_input}\")\n",
    "print(f\"Predicted Meaning: {predicted_text}\")"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "nvidiaTeslaT4",
   "dataSources": [
    {
     "datasetId": 5557640,
     "sourceId": 10887907,
     "sourceType": "datasetVersion"
    }
   ],
   "isGpuEnabled": true,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 7684.109212,
   "end_time": "2025-03-01T13:11:49.732446",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2025-03-01T11:03:45.623234",
   "version": "2.6.0"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {
     "0518e752354c42bb91db3c55a239dc72": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_allow_html": false,
       "layout": "IPY_MODEL_f7d1616852b046988afab58684e44f3b",
       "placeholder": "​",
       "style": "IPY_MODEL_1ffa3f2c70ad4004be99c1edfb870dfa",
       "tabbable": null,
       "tooltip": null,
       "value": " 1.72k/1.72k [00:00&lt;00:00, 170kB/s]"
      }
     },
     "096f822d753348278cb4bb80b644aba0": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "1144510c3b07403cbf292a7b4ff08071": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "12b3a347bccd430894132de43d1b866d": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "14e1958bfe0143a182e79db4fd084e63": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "15296179f44c4a22b5879e5a8b9a3abb": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "15dc6b094fb24665aa73155edcf383f2": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "1be2241f4bb04dc8a1be540c92a6cc27": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "FloatProgressModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "FloatProgressModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "ProgressView",
       "bar_style": "success",
       "description": "",
       "description_allow_html": false,
       "layout": "IPY_MODEL_8dc8931df8c34eeab5a02c83d62633d5",
       "max": 1355863.0,
       "min": 0.0,
       "orientation": "horizontal",
       "style": "IPY_MODEL_384541a55969454f838fc19cc7a3fcdd",
       "tabbable": null,
       "tooltip": null,
       "value": 1355863.0
      }
     },
     "1ce05d416ba04bb4934c1d8f6eea1ef5": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "StyleView",
       "background": null,
       "description_width": "",
       "font_size": null,
       "text_color": null
      }
     },
     "1d6f85c1e5874788a4c311462b7fcc05": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "1ffa3f2c70ad4004be99c1edfb870dfa": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "StyleView",
       "background": null,
       "description_width": "",
       "font_size": null,
       "text_color": null
      }
     },
     "21b9458ca2954560b5b78be2e5be362d": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "FloatProgressModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "FloatProgressModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "ProgressView",
       "bar_style": "success",
       "description": "",
       "description_allow_html": false,
       "layout": "IPY_MODEL_15296179f44c4a22b5879e5a8b9a3abb",
       "max": 557709915.0,
       "min": 0.0,
       "orientation": "horizontal",
       "style": "IPY_MODEL_fc5f2542077349018c6b5db77536bc0a",
       "tabbable": null,
       "tooltip": null,
       "value": 557709915.0
      }
     },
     "2c150bb20da7472db42d942629918064": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_allow_html": false,
       "layout": "IPY_MODEL_14e1958bfe0143a182e79db4fd084e63",
       "placeholder": "​",
       "style": "IPY_MODEL_6894c756b776447c9a5417f07499c928",
       "tabbable": null,
       "tooltip": null,
       "value": "tokenizer.json: 100%"
      }
     },
     "32e65b3ac03c4e5a83aaf4e9612b2172": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_allow_html": false,
       "layout": "IPY_MODEL_b073a204ded64dc4b6098e46cee3a135",
       "placeholder": "​",
       "style": "IPY_MODEL_46a2bbe9c09647408f91af8e1707a77d",
       "tabbable": null,
       "tooltip": null,
       "value": "model.safetensors: 100%"
      }
     },
     "34e2bf0fc76c44e584f7ad532c45fdfa": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_allow_html": false,
       "layout": "IPY_MODEL_15dc6b094fb24665aa73155edcf383f2",
       "placeholder": "​",
       "style": "IPY_MODEL_e1ea3416a34f4f8994544bc279a56ba7",
       "tabbable": null,
       "tooltip": null,
       "value": " 456k/456k [00:00&lt;00:00, 3.52MB/s]"
      }
     },
     "384541a55969454f838fc19cc7a3fcdd": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "ProgressStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "ProgressStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "StyleView",
       "bar_color": null,
       "description_width": ""
      }
     },
     "3f27e5b070e94ffeb38384891c07f5be": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "427217c3906c41f4a09d17cda8909c00": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "45e0f839c21a4a949eb55084710e14ef": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "ProgressStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "ProgressStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "StyleView",
       "bar_color": null,
       "description_width": ""
      }
     },
     "461ab60e7a184710900f08f898461486": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "46a2bbe9c09647408f91af8e1707a77d": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "StyleView",
       "background": null,
       "description_width": "",
       "font_size": null,
       "text_color": null
      }
     },
     "487d3d32fead47c198eb91afd436b500": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "520bfa2a9d8d4f4fa7802905064ae26c": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "StyleView",
       "background": null,
       "description_width": "",
       "font_size": null,
       "text_color": null
      }
     },
     "549e63ee12e4400aba6a5bf33b1faab7": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HBoxModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HBoxModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "HBoxView",
       "box_style": "",
       "children": [
        "IPY_MODEL_32e65b3ac03c4e5a83aaf4e9612b2172",
        "IPY_MODEL_21b9458ca2954560b5b78be2e5be362d",
        "IPY_MODEL_a06e15780d4c434c8fa15f8d78ddb955"
       ],
       "layout": "IPY_MODEL_427217c3906c41f4a09d17cda8909c00",
       "tabbable": null,
       "tooltip": null
      }
     },
     "59946a116e6d4564b33d04e8bbd8edf7": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "6828e63eef744d42b9f378c57fca24ac": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_allow_html": false,
       "layout": "IPY_MODEL_096f822d753348278cb4bb80b644aba0",
       "placeholder": "​",
       "style": "IPY_MODEL_1ce05d416ba04bb4934c1d8f6eea1ef5",
       "tabbable": null,
       "tooltip": null,
       "value": "merges.txt: 100%"
      }
     },
     "6894c756b776447c9a5417f07499c928": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "StyleView",
       "background": null,
       "description_width": "",
       "font_size": null,
       "text_color": null
      }
     },
     "6d85e86fb2da4b769945d3496deedc50": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HBoxModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HBoxModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "HBoxView",
       "box_style": "",
       "children": [
        "IPY_MODEL_a293545c191846dfb82ea063336ec533",
        "IPY_MODEL_6f3210be9124420bb3aebcd0528f0cc5",
        "IPY_MODEL_902a8e04c8374faab3bb5627e4301735"
       ],
       "layout": "IPY_MODEL_c24bf7f4bee4492ea7c0e39a2ec8dba7",
       "tabbable": null,
       "tooltip": null
      }
     },
     "6ddf5f199a904c63b4cbd7d3d0ce91bd": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "6f3210be9124420bb3aebcd0528f0cc5": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "FloatProgressModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "FloatProgressModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "ProgressView",
       "bar_style": "success",
       "description": "",
       "description_allow_html": false,
       "layout": "IPY_MODEL_86fcd86eb80e4c0784057b4088a13899",
       "max": 898823.0,
       "min": 0.0,
       "orientation": "horizontal",
       "style": "IPY_MODEL_45e0f839c21a4a949eb55084710e14ef",
       "tabbable": null,
       "tooltip": null,
       "value": 898823.0
      }
     },
     "732af43242374bf48a2fc7a4ed596b62": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HBoxModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HBoxModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "HBoxView",
       "box_style": "",
       "children": [
        "IPY_MODEL_2c150bb20da7472db42d942629918064",
        "IPY_MODEL_1be2241f4bb04dc8a1be540c92a6cc27",
        "IPY_MODEL_81a3368ef5b44f96a3ed1f3bea468839"
       ],
       "layout": "IPY_MODEL_461ab60e7a184710900f08f898461486",
       "tabbable": null,
       "tooltip": null
      }
     },
     "81a3368ef5b44f96a3ed1f3bea468839": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_allow_html": false,
       "layout": "IPY_MODEL_1d6f85c1e5874788a4c311462b7fcc05",
       "placeholder": "​",
       "style": "IPY_MODEL_8a54c43b279945c6b557fb0c93f75f47",
       "tabbable": null,
       "tooltip": null,
       "value": " 1.36M/1.36M [00:00&lt;00:00, 18.8MB/s]"
      }
     },
     "832f7e9b4a62412c83fd19616b0d4a60": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "86fcd86eb80e4c0784057b4088a13899": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "8843782d114c4062bdc2e30e5a8840ae": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HBoxModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HBoxModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "HBoxView",
       "box_style": "",
       "children": [
        "IPY_MODEL_f5ba4012480a4f04a4e52a318236c384",
        "IPY_MODEL_ba7a59d062984d4cafe5ba67fe29d3db",
        "IPY_MODEL_0518e752354c42bb91db3c55a239dc72"
       ],
       "layout": "IPY_MODEL_3f27e5b070e94ffeb38384891c07f5be",
       "tabbable": null,
       "tooltip": null
      }
     },
     "8a54c43b279945c6b557fb0c93f75f47": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "StyleView",
       "background": null,
       "description_width": "",
       "font_size": null,
       "text_color": null
      }
     },
     "8dc8931df8c34eeab5a02c83d62633d5": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "902a8e04c8374faab3bb5627e4301735": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_allow_html": false,
       "layout": "IPY_MODEL_bd1e2185b6f5480e956af2eae8caa826",
       "placeholder": "​",
       "style": "IPY_MODEL_d6c87297dba94565b4dbed8cf89a761a",
       "tabbable": null,
       "tooltip": null,
       "value": " 899k/899k [00:00&lt;00:00, 4.55MB/s]"
      }
     },
     "91b5a59a459a4f52a7da15432c0b93da": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "FloatProgressModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "FloatProgressModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "ProgressView",
       "bar_style": "success",
       "description": "",
       "description_allow_html": false,
       "layout": "IPY_MODEL_832f7e9b4a62412c83fd19616b0d4a60",
       "max": 456318.0,
       "min": 0.0,
       "orientation": "horizontal",
       "style": "IPY_MODEL_b1422fcb7d374392865587974bb39a53",
       "tabbable": null,
       "tooltip": null,
       "value": 456318.0
      }
     },
     "990f94a43cc54899b1ce9864629ac1af": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HBoxModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HBoxModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "HBoxView",
       "box_style": "",
       "children": [
        "IPY_MODEL_6828e63eef744d42b9f378c57fca24ac",
        "IPY_MODEL_91b5a59a459a4f52a7da15432c0b93da",
        "IPY_MODEL_34e2bf0fc76c44e584f7ad532c45fdfa"
       ],
       "layout": "IPY_MODEL_487d3d32fead47c198eb91afd436b500",
       "tabbable": null,
       "tooltip": null
      }
     },
     "a06e15780d4c434c8fa15f8d78ddb955": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_allow_html": false,
       "layout": "IPY_MODEL_59946a116e6d4564b33d04e8bbd8edf7",
       "placeholder": "​",
       "style": "IPY_MODEL_b6be53ba66d14574b76db6013f01fa32",
       "tabbable": null,
       "tooltip": null,
       "value": " 558M/558M [00:02&lt;00:00, 252MB/s]"
      }
     },
     "a293545c191846dfb82ea063336ec533": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_allow_html": false,
       "layout": "IPY_MODEL_12b3a347bccd430894132de43d1b866d",
       "placeholder": "​",
       "style": "IPY_MODEL_520bfa2a9d8d4f4fa7802905064ae26c",
       "tabbable": null,
       "tooltip": null,
       "value": "vocab.json: 100%"
      }
     },
     "b073a204ded64dc4b6098e46cee3a135": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "b1422fcb7d374392865587974bb39a53": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "ProgressStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "ProgressStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "StyleView",
       "bar_color": null,
       "description_width": ""
      }
     },
     "b6be53ba66d14574b76db6013f01fa32": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "StyleView",
       "background": null,
       "description_width": "",
       "font_size": null,
       "text_color": null
      }
     },
     "ba7a59d062984d4cafe5ba67fe29d3db": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "FloatProgressModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "FloatProgressModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "ProgressView",
       "bar_style": "success",
       "description": "",
       "description_allow_html": false,
       "layout": "IPY_MODEL_1144510c3b07403cbf292a7b4ff08071",
       "max": 1716.0,
       "min": 0.0,
       "orientation": "horizontal",
       "style": "IPY_MODEL_e0500b027661464887075e99c97b2f99",
       "tabbable": null,
       "tooltip": null,
       "value": 1716.0
      }
     },
     "bd1e2185b6f5480e956af2eae8caa826": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "c24bf7f4bee4492ea7c0e39a2ec8dba7": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "c2b7835a67374b999cd65c824c4aea92": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "StyleView",
       "background": null,
       "description_width": "",
       "font_size": null,
       "text_color": null
      }
     },
     "d6c87297dba94565b4dbed8cf89a761a": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "StyleView",
       "background": null,
       "description_width": "",
       "font_size": null,
       "text_color": null
      }
     },
     "e0500b027661464887075e99c97b2f99": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "ProgressStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "ProgressStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "StyleView",
       "bar_color": null,
       "description_width": ""
      }
     },
     "e1ea3416a34f4f8994544bc279a56ba7": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "StyleView",
       "background": null,
       "description_width": "",
       "font_size": null,
       "text_color": null
      }
     },
     "f5ba4012480a4f04a4e52a318236c384": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_allow_html": false,
       "layout": "IPY_MODEL_6ddf5f199a904c63b4cbd7d3d0ce91bd",
       "placeholder": "​",
       "style": "IPY_MODEL_c2b7835a67374b999cd65c824c4aea92",
       "tabbable": null,
       "tooltip": null,
       "value": "config.json: 100%"
      }
     },
     "f7d1616852b046988afab58684e44f3b": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "fc5f2542077349018c6b5db77536bc0a": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "ProgressStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "ProgressStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "StyleView",
       "bar_color": null,
       "description_width": ""
      }
     }
    },
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
